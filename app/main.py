import os
import shutil
import tarfile
import datetime
import logging
import json
import subprocess
import base64
import hashlib
import secrets
from typing import List, Dict, Optional

# ç¬¬ä¸‰æ–¹åº“
import httpx
from fastapi import FastAPI, UploadFile, BackgroundTasks, HTTPException, File, Depends, status
from fastapi.responses import HTMLResponse, JSONResponse
from fastapi.security import HTTPBasic, HTTPBasicCredentials
from fastapi.middleware.cors import CORSMiddleware
from apscheduler.schedulers.background import BackgroundScheduler
from apscheduler.triggers.cron import CronTrigger
from webdav4.client import Client as WebDavClient
from cryptography.fernet import Fernet
from pytz import timezone

# --- å…¨å±€é…ç½®ä¸å¸¸é‡ ---

DATA_DIR = "/data"
CONF_DIR = "/conf"
BACKUP_CONFIG_FILE = os.path.join(CONF_DIR, "backup_config.json")
LOG_FILE = os.path.join(CONF_DIR, "manager.log")
TEMP_DIR = "/tmp/backup_work"
TZ_CN = timezone('Asia/Shanghai')

# è¯»å–ç¯å¢ƒå˜é‡ä¸­çš„ç®¡ç†å‘˜è´¦å·å¯†ç ï¼Œé»˜è®¤ä¸º admin/admin
ADMIN_USER = os.getenv("DASHBOARD_ADMIN_USER", "admin")
ADMIN_PASS = os.getenv("DASHBOARD_ADMIN_PASSWORD", "admin")

# ç¡®ä¿å¿…è¦ç›®å½•å­˜åœ¨
os.makedirs(CONF_DIR, exist_ok=True)
os.makedirs(TEMP_DIR, exist_ok=True)

# æ—¥å¿—é…ç½®
logging.basicConfig(
    filename=LOG_FILE,
    level=logging.INFO,
    format='%(asctime)s [%(levelname)s] %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)
# åŒæ—¶è¾“å‡ºåˆ°æ§åˆ¶å°ä»¥ä¾¿ docker logs æŸ¥çœ‹
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
logging.getLogger().addHandler(console_handler)

app = FastAPI(title="Vaultwarden Dashboard")
security = HTTPBasic()

# å…è®¸è·¨åŸŸ
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# --- é‰´æƒå‡½æ•° ---

def check_auth(credentials: HTTPBasicCredentials = Depends(security)):
    """éªŒè¯ç”¨æˆ·åå’Œå¯†ç """
    # ä½¿ç”¨ secrets.compare_digest é˜²æ­¢æ—¶åºæ”»å‡»
    is_user_correct = secrets.compare_digest(credentials.username, ADMIN_USER)
    is_pass_correct = secrets.compare_digest(credentials.password, ADMIN_PASS)
    
    if not (is_user_correct and is_pass_correct):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password",
            headers={"WWW-Authenticate": "Basic"},
        )
    return credentials.username

# --- è¾…åŠ©åŠŸèƒ½å‡½æ•° ---

def load_config() -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    if os.path.exists(BACKUP_CONFIG_FILE):
        try:
            with open(BACKUP_CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logging.error(f"åŠ è½½é…ç½®å¤±è´¥: {e}")
    return {}

def save_config(config: dict):
    """ä¿å­˜é…ç½®æ–‡ä»¶ï¼Œå¹¶å°è¯•æ›´æ–°è°ƒåº¦ä»»åŠ¡"""
    with open(BACKUP_CONFIG_FILE, 'w', encoding='utf-8') as f:
        json.dump(config, f, indent=4, ensure_ascii=False)
    
    # å°è¯•é‡æ–°è°ƒåº¦
    try:
        schedule_backup_job(config)
    except Exception as e:
        logging.error(f"æ›´æ–°è°ƒåº¦ä»»åŠ¡å¤±è´¥: {e}")

def get_current_time_str():
    """è·å–å½“å‰åŒ—äº¬æ—¶é—´å­—ç¬¦ä¸²"""
    return datetime.datetime.now(TZ_CN).strftime("%Y%m%d_%H%M%S")

def send_telegram_notify(msg: str, success: bool = True):
    """å‘é€ Telegram é€šçŸ¥"""
    cfg = load_config()
    token = cfg.get("tg_bot_token")
    chat_id = cfg.get("tg_chat_id")
    
    if not token or not chat_id:
        return
    
    emoji = "âœ…" if success else "âŒ"
    title = "Vaultwarden å¤‡ä»½æˆåŠŸ" if success else "Vaultwarden å¤‡ä»½/è¿˜åŸå¤±è´¥"
    text = f"{emoji} *{title}*\n\n{msg}\n\nğŸ•’ æ—¶é—´: {datetime.datetime.now(TZ_CN).strftime('%Y-%m-%d %H:%M:%S')}"
    
    url = f"https://api.telegram.org/bot{token}/sendMessage"
    try:
        httpx.post(url, json={"chat_id": chat_id, "text": text, "parse_mode": "Markdown"}, timeout=10)
    except Exception as e:
        logging.error(f"Telegram å‘é€å¤±è´¥: {e}")

def get_fernet_key(password: str) -> bytes:
    """æ ¹æ®å¯†ç ç”Ÿæˆå›ºå®šçš„ AES Key (ä½¿ç”¨ SHA256 æ´¾ç”Ÿ)"""
    digest = hashlib.sha256(password.encode()).digest()
    return base64.urlsafe_b64encode(digest)

def encrypt_file(file_path: str, password: str) -> str:
    """åŠ å¯†æ–‡ä»¶ï¼Œè¿”å›æ–°è·¯å¾„ (.enc)"""
    key = get_fernet_key(password)
    fernet = Fernet(key)
    
    with open(file_path, 'rb') as f:
        data = f.read()
    
    encrypted_data = fernet.encrypt(data)
    out_path = file_path + ".enc"
    
    with open(out_path, 'wb') as f:
        f.write(encrypted_data)
        
    return out_path

def decrypt_file(file_path: str, password: str) -> str:
    """è§£å¯†æ–‡ä»¶ï¼Œè¿”å›å»é™¤äº† .enc çš„è·¯å¾„"""
    key = get_fernet_key(password)
    fernet = Fernet(key)
    
    with open(file_path, 'rb') as f:
        data = f.read()
    
    decrypted_data = fernet.decrypt(data)
    out_path = file_path.replace(".enc", "")
    
    with open(out_path, 'wb') as f:
        f.write(decrypted_data)
        
    return out_path

# --- GFS (Grandfather-Father-Son) ä¿ç•™ç­–ç•¥é€»è¾‘ ---

def parse_backup_date(filename: str) -> Optional[datetime.datetime]:
    """ä»æ–‡ä»¶åè§£ææ—¥æœŸ vw_backup_YYYYMMDD_HHMMSS"""
    try:
        # å‡è®¾æ ¼å¼å¦‚: vw_backup_20231001_120000.tar.gz.enc
        base = filename.split('.')[0] # å»æ‰åç¼€
        # æå– vw_backup_ åé¢çš„éƒ¨åˆ†
        parts = base.split('_')
        if len(parts) >= 3:
            date_str = f"{parts[2]}_{parts[3]}"
            dt = datetime.datetime.strptime(date_str, "%Y%m%d_%H%M%S")
            return dt.replace(tzinfo=TZ_CN)
    except Exception:
        return None
    return None

def apply_retention_policy(client: WebDavClient, remote_dir: str):
    """åº”ç”¨ GFS ç­–ç•¥æ¸…ç†æ—§å¤‡ä»½"""
    try:
        # æ³¨æ„ï¼šwebdav4 çš„ ls é»˜è®¤å¯èƒ½åªè¿”å›åå­—ï¼Œå¿…é¡»åŠ  detail=True æ‰èƒ½è·å–å®Œæ•´å­—å…¸ä¿¡æ¯
        files = client.ls(remote_dir, detail=True)
        backups = []
        
        # ç­›é€‰å¹¶è§£æå¤‡ä»½æ–‡ä»¶
        for f in files:
            # f æ˜¯ä¸€ä¸ªå­—å…¸ï¼ŒåŒ…å« name, size, type ç­‰
            if f['type'] == 'directory':
                continue
                
            name = f['name']
            if "vw_backup_" in name:
                dt = parse_backup_date(name)
                if dt:
                    backups.append({"name": name, "dt": dt, "path": name})
        
        # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
        backups.sort(key=lambda x: x['dt'], reverse=True)
        
        if not backups:
            return

        now = datetime.datetime.now(TZ_CN)
        to_keep = set()
        to_delete = set()

        # ç­–ç•¥å®šä¹‰
        keep_days = 7
        keep_weeks = 4
        keep_months = 12

        # 1. ä¿ç•™æœ€è¿‘ 7 å¤©çš„æ‰€æœ‰å¤‡ä»½
        for b in backups:
            if (now - b['dt']).days < keep_days:
                to_keep.add(b['name'])

        # 2. ä¿ç•™æœ€è¿‘ 4 å‘¨ï¼ˆæ¯å‘¨ä¸€ä»½ï¼Œå–è¯¥å‘¨æœ€æ–°çš„ï¼‰
        for i in range(keep_weeks):
            start_window = now - datetime.timedelta(weeks=i+1)
            end_window = now - datetime.timedelta(weeks=i)
            candidates = [b for b in backups if start_window <= b['dt'] < end_window]
            if candidates:
                to_keep.add(candidates[0]['name'])

        # 3. ä¿ç•™æœ€è¿‘ 12 ä¸ªæœˆï¼ˆæ¯æœˆä¸€ä»½ï¼Œå–è¯¥æœˆæœ€æ–°çš„ï¼‰
        for i in range(keep_months):
            start_window = now - datetime.timedelta(days=(i+1)*30)
            end_window = now - datetime.timedelta(days=i*30)
            candidates = [b for b in backups if start_window <= b['dt'] < end_window]
            if candidates:
                to_keep.add(candidates[0]['name'])

        # æ ‡è®°åˆ é™¤
        for b in backups:
            if b['name'] not in to_keep:
                to_delete.add(b['name'])

        # æ‰§è¡Œåˆ é™¤
        for name in to_delete:
            full_path = f"{remote_dir}/{name}".replace("//", "/")
            logging.info(f"GFS ç­–ç•¥æ¸…ç†: åˆ é™¤ {name}")
            client.remove(full_path)
            
    except Exception as e:
        logging.error(f"GFS æ¸…ç†è¿‡ç¨‹å‡ºé”™: {e}")

# --- æ ¸å¿ƒå¤‡ä»½é€»è¾‘ ---

def perform_backup():
    """æ‰§è¡Œå®Œæ•´çš„å¤‡ä»½æµç¨‹"""
    logging.info("å¼€å§‹æ‰§è¡Œå®šæ—¶å¤‡ä»½ä»»åŠ¡...")
    cfg = load_config()
    
    if not cfg.get("webdav_url"):
        logging.warning("æœªé…ç½® WebDAVï¼Œè·³è¿‡å¤‡ä»½ã€‚")
        return

    tmp_files = []
    backup_name = ""

    try:
        timestamp = get_current_time_str()
        backup_name = f"vw_backup_{timestamp}.tar.gz"
        tar_path = os.path.join(TEMP_DIR, backup_name)
        tmp_files.append(tar_path)

        # 1. å¤‡ä»½ SQLite æ•°æ®åº“
        sqlite_db_path = os.path.join(DATA_DIR, "db.sqlite3")
        backup_db_path = os.path.join(TEMP_DIR, "db.sqlite3")
        
        if os.path.exists(sqlite_db_path):
            logging.info("æ­£åœ¨å¯¼å‡º SQLite æ•°æ®åº“...")
            subprocess.run(["sqlite3", sqlite_db_path, f".backup '{backup_db_path}'"], check=True)
            tmp_files.append(backup_db_path)
        else:
            logging.warning("æœªæ‰¾åˆ° db.sqlite3ï¼Œå¯èƒ½æ˜¯é¦–æ¬¡è¿è¡Œã€‚")

        # 2. æ‰“åŒ…æ–‡ä»¶
        logging.info("æ­£åœ¨æ‰“åŒ…æ–‡ä»¶...")
        with tarfile.open(tar_path, "w:gz") as tar:
            if os.path.exists(backup_db_path):
                tar.add(backup_db_path, arcname="db.sqlite3")
            
            for item in ["attachments", "sends", "rsa_key.pem", "rsa_key.pub.pem", "config.json", "data.json", "icon_cache"]:
                p = os.path.join(DATA_DIR, item)
                if os.path.exists(p):
                    tar.add(p, arcname=item)
        
        # 3. åŠ å¯†
        upload_path = tar_path
        if cfg.get("encryption_password"):
            logging.info("æ­£åœ¨åŠ å¯†å¤‡ä»½æ–‡ä»¶...")
            upload_path = encrypt_file(tar_path, cfg["encryption_password"])
            tmp_files.append(upload_path)
            backup_name += ".enc"

        # 4. ä¸Šä¼ åˆ° WebDAV
        logging.info(f"æ­£åœ¨ä¸Šä¼ åˆ° WebDAV: {cfg['webdav_url']}")
        client = WebDavClient(
            cfg["webdav_url"], 
            auth=(cfg.get("webdav_user", ""), cfg.get("webdav_password", ""))
        )
        
        remote_dir = cfg.get('webdav_path', '/')
        # ç¡®ä¿è¿œç¨‹ç›®å½•å­˜åœ¨
        try:
            if remote_dir != "/":
                if not client.exists(remote_dir):
                    client.mkdir(remote_dir)
        except Exception as e:
             logging.warning(f"å°è¯•åˆ›å»ºç›®å½•å¤±è´¥(å¯èƒ½å·²å­˜åœ¨æˆ–æƒé™ä¸è¶³): {e}")

        remote_path = f"{remote_dir}/{backup_name}".replace("//", "/")
        
        # ã€ä¿®æ­£ã€‘webdav4 ä½¿ç”¨ upload_file æ–¹æ³•
        client.upload_file(upload_path, remote_path)
        logging.info("ä¸Šä¼ æˆåŠŸã€‚")
        
        # 5. æ‰§è¡Œ GFS ä¿ç•™ç­–ç•¥
        logging.info("æ­£åœ¨æ‰§è¡Œ GFS ä¿ç•™ç­–ç•¥...")
        apply_retention_policy(client, remote_dir)

        send_telegram_notify(f"å¤‡ä»½æ–‡ä»¶å·²ä¸Šä¼ : {backup_name}\nGFS ç­–ç•¥æ£€æŸ¥å®Œæˆã€‚")

    except Exception as e:
        logging.error(f"å¤‡ä»½æµç¨‹å¤±è´¥: {e}", exc_info=True)
        send_telegram_notify(f"å¤‡ä»½æµç¨‹å‘ç”Ÿå¼‚å¸¸: {str(e)}", success=False)
    finally:
        for f in tmp_files:
            if os.path.exists(f):
                try:
                    if os.path.isdir(f): shutil.rmtree(f)
                    else: os.remove(f)
                except:
                    pass

# --- è¿˜åŸé€»è¾‘ ---

def restart_vaultwarden():
    """é‡å¯ Vaultwarden è¿›ç¨‹"""
    logging.info("æ­£åœ¨é‡å¯ Vaultwarden...")
    try:
        subprocess.run(["supervisorctl", "restart", "vaultwarden"], check=True)
        logging.info("Vaultwarden é‡å¯å‘½ä»¤å·²å‘é€ã€‚")
    except subprocess.CalledProcessError as e:
        logging.error(f"é‡å¯ Vaultwarden å¤±è´¥: {e}")
        raise e

def process_restore_file(local_file_path: str):
    """å¤„ç†è¿˜åŸæ–‡ä»¶çš„æ ¸å¿ƒé€»è¾‘ï¼šè§£å¯† -> è§£å‹ -> è¦†ç›– -> é‡å¯"""
    cfg = load_config()
    temp_restored_files = []
    
    try:
        work_file = local_file_path

        # 1. è§£å¯†
        if local_file_path.endswith(".enc"):
            if not cfg.get("encryption_password"):
                raise ValueError("æ–‡ä»¶å·²åŠ å¯†ï¼Œä½†æœªé…ç½®è§£å¯†å¯†ç ï¼")
            logging.info("æ­£åœ¨è§£å¯†æ–‡ä»¶...")
            work_file = decrypt_file(local_file_path, cfg["encryption_password"])
            temp_restored_files.append(work_file)
        
        # 2. è§£å‹å¹¶è¦†ç›–
        logging.info("æ­£åœ¨è§£å‹è¦†ç›–æ•°æ®...")
        if not tarfile.is_tarfile(work_file):
            raise ValueError("æ–‡ä»¶ä¸æ˜¯æœ‰æ•ˆçš„ tar å½’æ¡£")

        subprocess.run(["supervisorctl", "stop", "vaultwarden"], check=False)

        with tarfile.open(work_file, "r:gz") as tar:
            tar.extractall(path=DATA_DIR)
        
        logging.info("æ•°æ®è¦†ç›–å®Œæˆã€‚")

        # 3. é‡å¯æœåŠ¡
        restart_vaultwarden()
        send_telegram_notify("ç³»ç»Ÿå·²æˆåŠŸä»å¤‡ä»½è¿˜åŸå¹¶é‡å¯ã€‚")

    except Exception as e:
        logging.error(f"è¿˜åŸå¤±è´¥: {e}", exc_info=True)
        send_telegram_notify(f"è¿˜åŸæ“ä½œå¤±è´¥: {str(e)}", success=False)
        subprocess.run(["supervisorctl", "start", "vaultwarden"], check=False)
    finally:
        if os.path.exists(local_file_path):
            os.remove(local_file_path)
        for f in temp_restored_files:
            if os.path.exists(f):
                os.remove(f)

def download_and_restore(filename: str):
    """åå°ä»»åŠ¡ï¼šä» WebDAV ä¸‹è½½å¹¶è¿˜åŸ"""
    cfg = load_config()
    local_path = os.path.join(TEMP_DIR, filename)
    
    try:
        logging.info(f"å¼€å§‹ä¸‹è½½å¤‡ä»½æ–‡ä»¶: {filename}")
        client = WebDavClient(
            cfg["webdav_url"], 
            auth=(cfg.get("webdav_user", ""), cfg.get("webdav_password", ""))
        )
        remote_path = f"{cfg.get('webdav_path', '/')}/{filename}".replace("//", "/")
        
        # ã€ä¿®æ­£ã€‘webdav4 ä½¿ç”¨ download_file æ–¹æ³•
        client.download_file(remote_path, local_path)
        
        process_restore_file(local_path)
    except Exception as e:
        logging.error(f"ä¸‹è½½/è¿˜åŸè¿‡ç¨‹å‡ºé”™: {e}")
        send_telegram_notify(f"ä¸‹è½½/è¿˜åŸè¿‡ç¨‹å‡ºé”™: {e}", success=False)

# --- è°ƒåº¦å™¨è®¾ç½® ---

scheduler = BackgroundScheduler(timezone=TZ_CN)

def schedule_backup_job(config: dict):
    """æ ¹æ®é…ç½®æ›´æ–°è°ƒåº¦ä»»åŠ¡"""
    if scheduler.get_job('backup_job'):
        scheduler.remove_job('backup_job')
    
    hour = int(config.get('schedule_hour', 3))
    minute = int(config.get('schedule_minute', 0))
    
    scheduler.add_job(
        perform_backup, 
        CronTrigger(hour=hour, minute=minute, timezone=TZ_CN), 
        id='backup_job',
        replace_existing=True
    )
    logging.info(f"å¤‡ä»½ä»»åŠ¡å·²è°ƒåº¦: æ¯å¤© {hour:02d}:{minute:02d}")

scheduler.start()
initial_cfg = load_config()
schedule_backup_job(initial_cfg)


# --- API è·¯ç”±å®šä¹‰ (é™¤æ ¹è·¯å¾„å¤–å…¨éƒ¨å¼€å¯é‰´æƒ) ---

@app.get("/", response_class=HTMLResponse)
async def read_root():
    """è¿”å›å‰ç«¯é¡µé¢ (ä¸éœ€è¦é‰´æƒ)"""
    index_path = "/app/static/index.html"
    if not os.path.exists(index_path):
        index_path = "app/static/index.html"
    
    if os.path.exists(index_path):
        with open(index_path, "r", encoding="utf-8") as f:
            return f.read()
    return "UI File Not Found. Please check deployment."

@app.get("/api/auth_check", dependencies=[Depends(check_auth)])
async def auth_check():
    """ç”¨äºå‰ç«¯éªŒè¯ Token æ˜¯å¦æœ‰æ•ˆ"""
    return {"status": "authenticated"}

@app.get("/api/config", dependencies=[Depends(check_auth)])
async def get_config():
    return load_config()

@app.post("/api/config", dependencies=[Depends(check_auth)])
async def update_config(config: dict):
    save_config(config)
    return {"status": "success", "message": "Configuration saved."}

@app.post("/api/backup/now", dependencies=[Depends(check_auth)])
async def trigger_backup_manual(background_tasks: BackgroundTasks):
    background_tasks.add_task(perform_backup)
    return {"status": "started", "message": "Backup started in background."}

@app.get("/api/backups", dependencies=[Depends(check_auth)])
async def list_backups():
    cfg = load_config()
    if not cfg.get("webdav_url"):
        return JSONResponse(status_code=400, content={"error": "WebDAV not configured"})
    
    try:
        client = WebDavClient(
            cfg["webdav_url"], 
            auth=(cfg.get("webdav_user", ""), cfg.get("webdav_password", ""))
        )
        # ã€ä¿®æ­£ã€‘å¿…é¡»åŠ ä¸Š detail=True æ‰èƒ½è¿”å›åŒ…å« name, size ç­‰ä¿¡æ¯çš„å­—å…¸åˆ—è¡¨
        files = client.ls(cfg.get('webdav_path', '/'), detail=True)
        
        backup_files = []
        for f in files:
            # ç¡®ä¿æ˜¯æ–‡ä»¶ä¸”åå­—åŒ…å« vw_backup_
            if f.get('type') != 'directory' and "vw_backup_" in f.get('name', ''):
                size_mb = round(int(f.get('size', 0)) / 1024 / 1024, 2)
                backup_files.append({
                    "name": f['name'],
                    "size": f"{size_mb} MB",
                    "last_modified": f.get('last_modified', '')
                })
        
        return sorted(backup_files, key=lambda x: x['name'], reverse=True)
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.post("/api/restore", dependencies=[Depends(check_auth)])
async def restore_from_cloud(file_name: str, background_tasks: BackgroundTasks):
    background_tasks.add_task(download_and_restore, file_name)
    return {"status": "started", "message": f"Restoring {file_name} in background..."}

@app.post("/api/upload_restore", dependencies=[Depends(check_auth)])
async def upload_and_restore(background_tasks: BackgroundTasks, file: UploadFile = File(...)):
    local_path = os.path.join(TEMP_DIR, file.filename)
    try:
        with open(local_path, "wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        background_tasks.add_task(process_restore_file, local_path)
        return {"status": "started", "message": "File uploaded. Restore starting in background..."}
    except Exception as e:
        return JSONResponse(status_code=500, content={"error": str(e)})

@app.get("/api/logs", dependencies=[Depends(check_auth)])
async def get_logs():
    if os.path.exists(LOG_FILE):
        try:
            with open(LOG_FILE, 'r', encoding='utf-8') as f:
                lines = f.readlines()
                return {"logs": "".join(lines[-100:])}
        except:
            return {"logs": "Error reading logs."}
    return {"logs": "No logs yet."}
